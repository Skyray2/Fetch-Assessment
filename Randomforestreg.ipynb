{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "class MyRandomForestRegressor:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_estimators):\n",
    "            bootstrap_indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_bootstrap = X[bootstrap_indices]\n",
    "            y_bootstrap = y[bootstrap_indices]\n",
    "            \n",
    "            tree = DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_samples_leaf=self.min_samples_leaf\n",
    "            )\n",
    "            tree.fit(X_bootstrap, y_bootstrap)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(len(X))\n",
    "        for tree in self.trees:\n",
    "            tree_predictions = tree.predict(X)\n",
    "            predictions += tree_predictions\n",
    "        return predictions / len(self.trees)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forecast monthly births with random forest\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    "\n",
    "# fit an random forest model and make a one step prediction\n",
    "def random_forest_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = MyRandomForestRegressor(n_estimators=1000)\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict([testX])\n",
    "\treturn yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = random_forest_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    "\n",
    "# load the dataset\n",
    "series = read_csv('data_daily.csv', header=0, index_col=0)\n",
    "values = series.values\n",
    "n_in=17\n",
    "# transform the time series data into supervised learning\n",
    "data = series_to_supervised(values, n_in)\n",
    "# evaluate\n",
    "mae, y, yhat = walk_forward_validation(data, 12)\n",
    "print('MAE: %.3f' % mae)\n",
    "# plot expected vs predicted\n",
    "pyplot.plot(y, label='Expected')\n",
    "pyplot.plot(yhat, label='Predicted')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from pandas import read_csv\n",
    "n_in=17\n",
    "series = read_csv('data_daily.csv', header=0, index_col=0)\n",
    "values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "train = series_to_supervised(values, n_in)\n",
    "# split into input and output columns\n",
    "trainX, trainy = train[:, :-1], train[:, -1]\n",
    "# fit model\n",
    "model = MyRandomForestRegressor(n_estimators=1000)\n",
    "model.fit(trainX, trainy)\n",
    "pickle.dump(model, open('rfmodel.pkl','wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct an input for a new prediction\n",
    "for i in range(366):\n",
    "    row = values[-n_in:].flatten()\n",
    "    # make a one-step prediction\n",
    "    yhat = model.predict(asarray([row]))\n",
    "    print('Input: %s, Predicted: %.3f' % (row[-1], yhat[0]))\n",
    "    values=np.append(values,[yhat[0]]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pyplot.plot(values, label='Predicted')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = read_csv('data_daily.csv', header=0, index_col=0)\n",
    "truevalues = series.values\n",
    "n_in=17\n",
    "data = series_to_supervised(truevalues, n_in)\n",
    "# evaluate\n",
    "mae, y, yhat = walk_forward_validation(data, 40)\n",
    "residuals=y-yhat\n",
    "import pandas as pd\n",
    "from arch import arch_model\n",
    "\n",
    "# Assuming 'residuals' is a pandas Series containing the residuals\n",
    "# Specify the GARCH model order (p and q) and other parameters\n",
    "garch_model = arch_model(residuals, vol='Garch', p=1, q=1)\n",
    "\n",
    "# Fit the GARCH model\n",
    "garch_model_fit = garch_model.fit()\n",
    "\n",
    "# Display model summary\n",
    "print(garch_model_fit.summary())\n",
    "\n",
    "# Get volatility forecasts for future periods\n",
    "forecast_horizon = 5  # Adjust as needed\n",
    "forecast = garch_model_fit.forecast(horizon=forecast_horizon)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have the GARCH model and Random Forest predictions\n",
    "# garch_model = arch_model(residuals, vol='Garch', p=1, q=1)\n",
    "# rf_predictions = ...  # Replace with your Random Forest predictions\n",
    "\n",
    "# Set the desired confidence level (e.g., 95%)\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Calculate the z-score for the desired confidence level\n",
    "from scipy.stats import norm\n",
    "z_score = norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "\n",
    "# Get the last forecasted volatility value from the GARCH model\n",
    "last_forecasted_volatility = garch_model_fit.forecast(horizon=1).variance.iloc[-1, :].values[0]\n",
    "\n",
    "# Calculate the margin of error\n",
    "margin_of_error = z_score * np.sqrt(last_forecasted_volatility)\n",
    "\n",
    "# Calculate the lower and upper bounds of the prediction interval\n",
    "lower_bound = values - margin_of_error\n",
    "upper_bound = values + margin_of_error\n",
    "\n",
    "print(\"Prediction Interval for {}% Confidence:\".format(int(confidence_level * 100)))\n",
    "for i in range(365,len(values)):\n",
    "    print('>Lower=%.1f,Prediction=%.1f, Upper=%.1f' % (lower_bound[i],values[i],upper_bound[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals=y-yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from arch import arch_model\n",
    "\n",
    "# Assuming 'residuals' is a pandas Series containing the residuals\n",
    "# Specify the GARCH model order (p and q) and other parameters\n",
    "garch_model = arch_model(residuals, vol='Garch', p=1, q=1)\n",
    "\n",
    "# Fit the GARCH model\n",
    "garch_model_fit = garch_model.fit()\n",
    "\n",
    "# Display model summary\n",
    "print(garch_model_fit.summary())\n",
    "\n",
    "# Get volatility forecasts for future periods\n",
    "forecast_horizon = 5  # Adjust as needed\n",
    "forecast = garch_model_fit.forecast(horizon=forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming you have the GARCH model and Random Forest predictions\n",
    "# garch_model = arch_model(residuals, vol='Garch', p=1, q=1)\n",
    "# rf_predictions = ...  # Replace with your Random Forest predictions\n",
    "\n",
    "# Set the desired confidence level (e.g., 95%)\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Calculate the z-score for the desired confidence level\n",
    "from scipy.stats import norm\n",
    "z_score = norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "\n",
    "# Get the last forecasted volatility value from the GARCH model\n",
    "last_forecasted_volatility = garch_model_fit.forecast(horizon=1).variance.iloc[-1, :].values[0]\n",
    "\n",
    "# Calculate the margin of error\n",
    "margin_of_error = z_score * np.sqrt(last_forecasted_volatility)\n",
    "\n",
    "# Calculate the lower and upper bounds of the prediction interval\n",
    "lower_bound = values - margin_of_error\n",
    "upper_bound = values + margin_of_error\n",
    "\n",
    "print(\"Prediction Interval for {}% Confidence:\".format(int(confidence_level * 100)))\n",
    "for i in range(365,len(values)):\n",
    "    print('>Lower=%.1f,Prediction=%.1f, Upper=%.1f' % (lower_bound[i],values[i],upper_bound[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(values, label='Predicted')\n",
    "pyplot.plot(lower_bound, label='Lower')\n",
    "pyplot.plot(upper_bound, label='Upper')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = read_csv('data_daily.csv')\n",
    "df['Date'] = pd.to_datetime(df['# Date'])\n",
    "\n",
    "# Set the Date column as the DataFrame's index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Resample the daily data to monthly and sum the 'receipt_count' for each month\n",
    "monthly_data = df['Receipt_Count'].resample('M').sum()\n",
    "\n",
    "# Create a new DataFrame with the monthly totals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from pandas import read_csv\n",
    "values = monthly_data.values\n",
    "values=values.reshape(-1,1)\n",
    "# transform the time series data into supervised learning\n",
    "train = series_to_supervised(values, n_in=6)\n",
    "# split into input and output columns\n",
    "trainX, trainy = train[:, :-1], train[:, -1]\n",
    "# fit model\n",
    "modelMonth = MyRandomForestRegressor(n_estimators=1000)\n",
    "modelMonth.fit(trainX, trainy)\n",
    "pickle.dump(model, open('modelMonth.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct an input for a new prediction\n",
    "for i in range(12):\n",
    "    row = values[-6:].flatten()\n",
    "    # make a one-step prediction\n",
    "    yhat = modelMonth.predict(asarray([row]))\n",
    "    print('Input: %s, Predicted: %.3f' % (row, yhat[0]))\n",
    "    values=np.append(values,[yhat[0]]).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(values, label='Predicted')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "\n",
    "forecast_period = 365\n",
    "series = read_csv('data_daily.csv', header=0, index_col=0)\n",
    "train_data = series.values\n",
    "\n",
    "# Fit data \n",
    "model = ExponentialSmoothing(\n",
    "    train_data,\n",
    "    seasonal_periods=4,\n",
    "    trend=\"add\",\n",
    "    seasonal=\"add\",\n",
    "    use_boxcox=True,\n",
    "    initialization_method=\"estimated\",\n",
    ").fit()\n",
    "\n",
    "# Forecast next 5 periods\n",
    "forecast = model.forecast(forecast_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(series.values, label='Expected')\n",
    "pyplot.plot(forecast,label='Predicted')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
